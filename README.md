# GPU Tensor Lifetime Verifier

A **Rust + CUDA runtime prototype** that detects **asynchronous GPU use-after-free bugs** by verifying tensor lifetimes with **CUDA events**.

This project demonstrates how Rust ownership and RAII can be extended beyond CPU memory to reason about **GPU execution timelines**, a problem faced by deep learning frameworks, GPU runtimes, and driver-level systems.

---

## ğŸš€ Why This Project Exists

GPU kernels execute **asynchronously** with respect to the CPU. This makes memory safety extremely hard:

* The CPU may free GPU memory **while a kernel is still running**
* Rustâ€™s borrow checker cannot see GPU execution
* Bugs manifest as **silent corruption or crashes**

This project builds a **runtime verifier** that:

* Tracks when a GPU tensor was last used
* Associates that use with a **CUDA event**
* Prevents deallocation until the GPU has finished execution

If a tensor is dropped too early, the program **fails loudly and deterministically**.

---

## ğŸ§  Core Idea (One Sentence)

> A GPU tensor is safe to free **only after the CUDA event recorded after its last kernel launch has completed**.

---

## ğŸ—ï¸ Architecture Overview

```
Rust (Host)
 â””â”€â”€ Tensor<T>
     â”œâ”€â”€ Owns GPU memory (cudaMalloc / cudaFree)
     â”œâ”€â”€ Tracks last CUDA event
     â”œâ”€â”€ Records event after kernel launch
     â””â”€â”€ Verifies event completion on Drop

C / CUDA (Device Runtime)
 â”œâ”€â”€ Memory allocation helpers
 â”œâ”€â”€ CUDA event management
 â””â”€â”€ Asynchronous CUDA kernels
```

Rust never talks to CUDA directly. All interactions go through a **C-compatible CUDA wrapper**, keeping the unsafe boundary explicit and minimal.

---

## ğŸ“ Project Structure

```
gpu-tensor-lifetime-verifier/
â”œâ”€â”€ cuda/
â”‚   â””â”€â”€ cuda_api.cu        # CUDA memory, events, and kernels
â”œâ”€â”€ rust/
â”‚   â”œâ”€â”€ main.rs            # Demo + bug trigger
â”‚   â””â”€â”€ tensor.rs          # Tensor abstraction + lifetime verifier
â””â”€â”€ libcudawrap.so         # CUDA shared library (built locally)
```

---

## ğŸ”’ Safety Model

### What Is Guaranteed

* GPU memory is freed **exactly once**
* No tensor can be dropped while the GPU is still using it
* Async use-after-free bugs are detected at runtime

### What Is Not Attempted

* Compile-time GPU lifetime proofs
* Multi-GPU or multi-stream correctness
* Performance optimization

This is a **correctness-first runtime prototype**.

---

## âš™ï¸ How Lifetime Verification Works

1. A CUDA kernel is launched asynchronously
2. A CUDA event is recorded immediately after launch
3. The event is stored inside the owning `Tensor`
4. When the tensor is dropped:

   * The runtime queries the event
   * If the GPU has not finished â†’ **panic**

This mirrors how real GPU runtimes reason about execution progress.

---

## ğŸ§ª Demonstrated Bug Detection

The demo intentionally triggers a real GPU bug:

```rust
{
    let mut t = Tensor::<f32>::new(1_000_000);
    t.add_one();          // async kernel launch
} // tensor dropped too early
```

### Runtime Output

```
Kernel launched, tensor will now go out of scope
thread 'main' panicked at 'Tensor dropped while GPU is still using it!'
```

This confirms the verifier correctly detects **async GPU use-after-free**.

---

## ğŸ› ï¸ Build & Run

### Prerequisites

* Linux (tested on WSL2)
* NVIDIA GPU + CUDA Toolkit
* Rust toolchain

### Build CUDA Library

```bash
nvcc -Xcompiler -fPIC -shared cuda/cuda_api.cu -o libcudawrap.so
```

### Build & Run Rust Demo

```bash
cd rust
rustc main.rs -L .. -l cudawrap -o main
LD_LIBRARY_PATH=.. ./main
```

---

## ğŸ“Œ Key Learnings

* GPU memory safety cannot be reasoned about without execution timelines
* Rust ownership can be extended to **foreign, asynchronous systems**
* CUDA events are the minimal primitive needed for correctness
* Runtime verification is often the only practical solution

---

## ğŸ¯ Who This Is For

* GPU runtime / driver engineers
* Systems programmers working near hardware
* Deep learning framework developers
* Compiler and runtime researchers

---

## ğŸ”® Possible Extensions

* Stream-aware lifetime tracking
* Multi-tensor dependency graphs
* Deterministic execution modes
* Cargo + build.rs integration
* Static + runtime hybrid verification

---

## âš ï¸ Disclaimer

This project is a **research and learning prototype**. It is not intended for production use, but demonstrates core ideas used in real GPU runtimes and deep learning systems.
